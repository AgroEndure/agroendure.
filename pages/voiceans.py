import streamlit as st
from audio_recorder_streamlit import audio_recorder
import openai
from gtts import gTTS
import os

# Function to set up OpenAI API key
def setup_openai_client(api_key):
    openai.api_key = api_key

# Function to transcribe Urdu audio
def transcribe_audio(audio_path):
    try:
        with open(audio_path, "rb") as audio_file:
            transcript = openai.Audio.transcribe(
                model="whisper-1", 
                file=audio_file,
                language="ur"
            )
        return transcript["text"].strip()  # Ensure proper extraction
    except Exception as e:
        return f"âš ï¸ Ø®Ø±Ø§Ø¨ÛŒ ÛÙˆØ¦ÛŒ: {str(e)}"

# Function to get AI response in Urdu
def fetch_ai_response(input_text):
    if not input_text:  # Prevent empty requests
        return "Ù…Ø¹Ø°Ø±Øª! Ù…ÛŒÚº Ø¢Ù¾ Ú©ÛŒ Ø¨Ø§Øª Ù†ÛÛŒÚº Ø³Ù† Ø³Ú©Ø§Û” Ø¨Ø±Ø§Û Ú©Ø±Ù… Ø¯ÙˆØ¨Ø§Ø±Û Ø¨ÙˆÙ„ÛŒÚºÛ”"
    
    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo-1106", 
            messages=[{"role": "user", "content": input_text}],
            temperature=0.7,
            max_tokens=4000
        )
        return response["choices"][0]["message"]["content"]
    except Exception as e:
        return f"âš ï¸ AI Ø³Û’ Ø¬ÙˆØ§Ø¨ Ø­Ø§ØµÙ„ Ú©Ø±Ù†Û’ Ù…ÛŒÚº Ù…Ø³Ø¦Ù„Û ÛÙˆØ§: {str(e)}"

# Convert text to Urdu speech using Google TTS
def text_to_audio(text, audio_path):
    tts = gTTS(text=text, lang='ur')
    tts.save(audio_path)

# Streamlit UI
def main():
    st.sidebar.title("ğŸ”‘ API KEY CONFIGURATION")
    api_key = st.sidebar.text_input("Ø§Ù¾Ù†Ø§ OpenAI API Ú©Ù„ÛŒØ¯ Ø¯Ø±Ø¬ Ú©Ø±ÛŒÚº", type="password")
    
    st.title("ğŸ—£ï¸ Aurora SpeakEasy - Ø§Ø±Ø¯Ùˆ")
    st.write("Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÛŒÚ©Ù…! Ù…Ø¬Ú¾ Ø³Û’ Ø¨Ø§Øª Ú©Ø±Ù†Û’ Ú©Û’ Ù„Ø¦Û’ Ù†ÛŒÚ†Û’ Ø±ÛŒÚ©Ø§Ø±ÚˆÙ†Ú¯ Ú©Ø§ Ø¨Ù¹Ù† Ø¯Ø¨Ø§Ø¦ÛŒÚºÛ”")

    if api_key:
        setup_openai_client(api_key)
        recorded_audio = audio_recorder()

        if recorded_audio:
            audio_file = "audio.mp3"
            with open(audio_file, "wb") as f:
                f.write(recorded_audio)

            st.write("ğŸ™ï¸ **Ø±ÛŒÚ©Ø§Ø±Úˆ Ø´Ø¯Û Ø¢ÚˆÛŒÙˆ Ù¾Ø±ÙˆØ³ÛŒØ³Ù†Ú¯ Ù…ÛŒÚº ÛÛ’...**")
            
            transcribed_text = transcribe_audio(audio_file)
            
            if not transcribed_text or transcribed_text.startswith("âš ï¸"):  # Handle errors
                st.write(transcribed_text)
                return  

            st.write("ğŸ“ **ØªØ­Ø±ÛŒØ±ÛŒ Ù…ØªÙ†:** ", transcribed_text)

            ai_response = fetch_ai_response(transcribed_text)

            response_audio_file = "audio_response.mp3"
            text_to_audio(ai_response, response_audio_file)
            
            st.audio(response_audio_file)
            st.write("ğŸ¤– **AI Ú©Ø§ Ø¬ÙˆØ§Ø¨:** ", ai_response)

if __name__ == "__main__":
    main()


